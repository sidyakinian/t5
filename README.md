![1*D0J1gNQf8vrrUpKeyD8wPA](https://user-images.githubusercontent.com/34050187/217142459-6b3e56d5-16e9-458e-a4a8-c4ed1114626f.png)

# Implementation of T5 transformer model in PyTorch and JAX

The T5 transformer model is a natural language processing model developed by Google. It uses the transformer architecture, which has been widely adopted in NLP for processing and understanding long sequences of text data. T5 is capable of performing a variety of NLP tasks, including text classification, machine translation, and summarization. The model is trained on a large dataset, which helps it produce coherent text and perform NLP tasks with a high level of accuracy.

This repository implements T5 using two deep learning frameworks: PyTorch and JAX. The goal of this project is to provide a simple example of a working transformer implementation.

### Credits

* [Useful article](https://e2eml.school/transformers.html#rest_stop) for understanding transformers.
* HuggingFace implementations of T5 have been very helpful.
